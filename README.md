# TasteIQ

> **Personalized restaurant and meal recommendations powered by Retrieval-Augmented Generation (RAG) and fine-tuned LLMs.**

---

## ğŸ§  Overview

**TasteIQ** is a GenAI-driven system that helps users discover and plan meals based on their preferences, dietary goals, and restaurant availability.

Using a **Retrieval-Augmented Generation (RAG)** pipeline, the system combines:
- **Structured data** from the Spoonacular API (menu items, nutrition, recipes, restaurants)
- **Fine-tuned GPT-3.5 models** for cuisine-specific expertise (e.g. Asian, Mexican, Fast Food)
- **GPT-4o** for reasoning, personalization, and recommendation synthesis  

The result is an intelligent conversational agent that can answer queries like:

> â€œFind me a vegan fast-food meal under 600 calories.â€  
> â€œRecommend high-protein Mexican dishes for post-workout recovery.â€  
> â€œWhatâ€™s a balanced dinner option from Chipotle today?â€

---

## ğŸ§© Core Features

| Feature | Description |
|----------|-------------|
| ğŸ” **Restaurant-Aware Search** | Integrates with Spoonacularâ€™s restaurant and menu item endpoints to retrieve real fast-food and chain options. |
| ğŸ§¬ **Nutrition Intelligence** | Automatically analyzes and ranks meals based on macronutrients, calories, and dietary constraints. |
| ğŸ§  **RAG-Based Question Answering** | Combines structured nutritional data with GPT reasoning for factual, context-aware answers. |
| ğŸŒ **Cuisine-Specific Personalization** | Uses fine-tuned GPT-3.5 models per cuisine type for nuanced recommendations. |
| ğŸ’¬ **Conversational AI Interface** | GPT-4o handles user queries and natural dialogue for a seamless chat experience. |
| â˜ï¸ **Cloud-Native Deployment** | Containerized with Docker and deployable on AWS ECS/Fargate for scalable serving. |

---

## ğŸ§± Planned Architecture

```plaintext
backend/
â”œâ”€â”€ app.py                    # FastAPI / Flask backend entrypoint
â”œâ”€â”€ api/                      # API routing layer
â”‚   â”œâ”€â”€ routes.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ services/                 # External service integrations
â”‚   â”œâ”€â”€ spoonacular_api.py
â”‚   â”œâ”€â”€ openai_service.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ database/                 # Data ingestion & query logic
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ ingest_data.py
â”‚   â””â”€â”€ queries.py
â”œâ”€â”€ rag/                      # RAG pipeline components
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ fine_tune/                # Fine-tuning scripts & examples
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â”œâ”€â”€ upload_and_train.py
â”‚   â””â”€â”€ examples/
â”œâ”€â”€ utils/                    # Helper functions
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â””â”€â”€ helpers.py
â””â”€â”€ tests/                    # Unit and integration tests
    â””â”€â”€ test_api.py
```

## ğŸ” System Design

### 1ï¸âƒ£ Data Layer
- Pulls real-time menu and nutrition data from **Spoonacular API**  
- Normalizes and stores it in a local or cloud database (**SQLite â†’ PostgreSQL/RDS**)  
- Enriches data with embeddings for retrieval (**Weaviate**)

### 2ï¸âƒ£ RAG Pipeline
- User queries are vectorized and matched against stored embeddings  
- Retrieved context is combined with **GPT-4o** prompt templates  
- GPT synthesizes structured + unstructured information into natural answers

### 3ï¸âƒ£ Fine-Tuning Layer
- **GPT-3.5** models are fine-tuned per cuisine domain *(Asian, Mexican, Fast Food, etc.)*  
- Fine-tuned models can be dynamically selected based on cuisine classification of the query

### 4ï¸âƒ£ Deployment Layer
- Packaged via **Docker**  
- Deployable to **AWS ECS/Fargate** or **Lambda (serverless option)**  
- **S3** for data/artifact storage, **CloudWatch** for logs/metrics

---

## ğŸ§® Example Query Flow

**User:**  
> â€œI want a low-carb dinner from a fast-food place.â€

**RAG Retriever:**  
Fetches relevant menu items from Spoonacular (low-carb tagged)

**GPT-4o Reasoning:**  
Filters by location, taste profile, and dietary rules

**Response:**  
> â€œTry *Grilled Chicken Salad* from Chick-fil-A â€” only **8g net carbs** and **320 calories**.â€

---

## ğŸ§° Tech Stack

| Layer | Tools |
|-------|-------|
| **Backend** | Python, FastAPI |
| **Model Serving** | OpenAI GPT-4o, GPT-3.5 fine-tunes |
| **Data Ingestion** | Spoonacular API, Pandas |
| **Database** | SQLite / PostgreSQL (AWS RDS optional) |
| **Vector Store** | Weaviate |
| **Retrieval Augmented Generation** | LlamaIndex |
| **MLOps / Deployment** | Docker, AWS ECS/Fargate, S3, CloudWatch |
| **Version Control** | Git + GitHub Actions (CI/CD planned) |

---

## ğŸ§‘â€ğŸ³ Future Enhancements
- ğŸ” Continuous fine-tuning pipeline using real user feedback  
- ğŸ‹ï¸ Fitness integration (Fitbit / Apple Health APIs)  
- ğŸ§  User preference memory for long-term personalization  
- ğŸ“Š Evaluation dashboard comparing base GPT-4o vs fine-tuned GPT-3.5 responses  
- ğŸ’¬ Multi-turn dialogue state management for richer conversations  
- ğŸ§© LangChain integration for modular orchestration  

---

## ğŸš€ Deployment Plan

| Stage | Goal |
|--------|------|
| **Phase 1** | Local development, Spoonacular ingestion, simple RAG prototype |
| **Phase 2** | GPT-4o integration + API deployment via FastAPI |
| **Phase 3** | Fine-tune GPT-3.5 models by cuisine type |
| **Phase 4** | Containerize and deploy to AWS ECS (free tier) |
| **Phase 5** | Add automated tests and CI/CD workflow |

---

## ğŸ“¦ Installation (Planned)

```bash
# Clone the repo
git clone https://github.com/<yourusername>/TasteIQ
cd TasteIQ/backend

# Set up virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env

# Run locally
python app.py
